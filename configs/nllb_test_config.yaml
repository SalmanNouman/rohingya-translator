model:
  base_model_name: "facebook/nllb-200-distilled-600M"
  max_length: 32
  src_lang: "eng_Latn"
  tgt_lang: "ben_Beng"

data:
  train_file: "data/processed/train"
  valid_file: "data/processed/val"
  max_length: 32

training:
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  num_train_epochs: 1
  learning_rate: 1e-5
  warmup_steps: 0
  logging_steps: 1
  save_steps: 100
  eval_steps: 100
  output_dir: "outputs/nllb_test"
  fp16: false
  gradient_accumulation_steps: 1
